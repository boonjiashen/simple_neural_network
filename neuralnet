#!/usr/bin/python
"""Perform K-folds cross-validation on a simple neural network. Data is read
from a ARFF file. Results are written to stdout.
"""

import optparse
import math
import random
import utils
from SimpleNeuralNetwork import SimpleNeuralNetwork

def mean(list_of_numbers):
    """Returns the arithmetic mean of a list of numbers
    """
    return 1. * sum(list_of_numbers) / len(list_of_numbers)


if __name__ == "__main__":


    ######################### Parse arguments #################################

    parser = optparse.OptionParser()
    options, args = parser.parse_args()
    assert len(args) == 4

    # Positional argument 1: name of training set file
    # Positional argument 2: number of folds for cross-validation
    # Positional argument 3: learning rate of stochastic gradient descent
    # Positional argument 4: number of epochs for training
    filename, n_folds, learning_rate, n_epochs = args
    n_folds = int(n_folds)
    learning_rate = float(learning_rate)
    n_epochs = int(n_epochs)


    ######################### Declare inputs for learning #####################

    # Load dataset X and labels y from ARFF file
    X, y, negative_label, positive_label =  \
            utils.load_binary_class_data(filename)

    # Size of data set
    n_instances = len(X)

    # Size of each feature vector
    n_feat = len(X[0])


    ######################### Train neural network ############################

    # Values to be written in output file
    predictions = n_instances * [None]  # list of labels according to ARFF file
    outputs = n_instances * [None]  # list of numbers according to ANN output
    fold_assignments = n_instances * [None]  # numbers in interval [1, n_folds]

    # Fold of the test set. We start with n_folds and decrement to 1
    test_fold_assignment = n_folds

    # Perform k folds cross validation
    # Each scheme is a 2-ple of indices for the training set and test set
    partition_scheme_generator = utils.generate_stratified_train_test_indices(y,
            n_folds, randomize=True)
    for training_inds, test_inds in partition_scheme_generator:

        # Initialize network
        ann = SimpleNeuralNetwork(n_feat)

        # Train network by stochastic gradient descent
        for training_ind in n_epochs * training_inds:
            instance, label = X[training_ind], y[training_ind]
            ann.train(instance, label, learning_rate=learning_rate)

        # Get non-binarized and binarized predictions of test set
        for ti in test_inds:
            instance = X[ti]
            predictions[ti] = positive_label  \
                    if ann.predict(instance) == 1 \
                    else negative_label
            outputs[ti] = ann.output(instance)

        # Remember in which fold was each instance in the test set
        for ti in test_inds:
            fold_assignments[ti] = test_fold_assignment

        # Decrement fold value for next partition scheme
        test_fold_assignment = test_fold_assignment - 1


    ######################### Write output to stdout ##########################
    
    # Our program should do stratified cross validation with the specified
    # number of folds. As output, it should print one line for each instance
    # (in the same order as the data file) indicating (i) the fold to which the
    # instance was assigned (1 to n), (ii) the predicted class, (iii) the
    # actual class, (iv) the confidence of the instance being positive (i.e.
    # the output of the sigmoid).

    for ii in range(n_instances):  # index of instance
        true_label = positive_label  \
                if y[ii] == 1 \
                else negative_label
        print "%i %s %s %f" % (
                fold_assignments[ii],
                predictions[ii],
                true_label,
                outputs[ii]
                )
